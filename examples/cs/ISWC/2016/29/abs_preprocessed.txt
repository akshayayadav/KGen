Linked Open Data has been recognized as a valuable source for background information in data mining.
However, most data mining tools require a vector of numerical features associated with an instance, while Linked Open Data sources are graphs by nature.
However, most data mining tools require a vector of nominal features associated with an instance, while Linked Open Data sources are graphs by nature.
However, most data mining tools require features in propositional form associated with an instance, while Linked Open Data sources are graphs by nature.
In this paper, we present RDF2Vec, an approach.
an approach that uses language modeling approaches for unsupervised feature extraction from sequences of words for unsupervised feature extraction to RDF graphs.
an approach that uses adapts language modeling approaches for unsupervised feature extraction to RDF graphs.
graph walks.
We generate sequences by leveraging local information from graph sub-structures.
graph sub-structures harvested by Weisfeiler-Lehman Subtree RDF Graph Kernels.
graph learn latent numerical representations of entities in RDF graphs.
We evaluation shows that feature vector representations of general knowledge graphs such as DBpedia can be easily reused for different tasks.
We evaluation shows that feature vector representations of general knowledge graphs such as Wikidata can be easily reused for different tasks.
We evaluation shows that such vector representations outperform existing techniques for the propositionalization of RDF graphs on a variety of different predictive machine learning tasks.