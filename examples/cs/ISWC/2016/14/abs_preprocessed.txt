Advances in information extraction have enabled the automatic construction of large knowledge graphs like YAGO.
Advances in information extraction have enabled the automatic construction of large knowledge graphs like Wikidata.
Advances in information extraction have enabled the automatic construction of large knowledge graphs like Freebase.
Advances in information extraction have enabled the automatic construction of large knowledge graphs like DBpedia.
These large knowledge graphs are inevitably bound to be incomplete.
To fill in the gaps, data correlations in the large knowledge graph can be analyzed to infer Horn rules.
To fill in the gaps, data correlations in the large knowledge graph can be analyzed to predict new facts.
However, Horn rules do not take into account possible exceptions, so that predicting facts via such rules introduces errors.
To overcome this problem, we present a method for effective revision of learned Horn rules by adding i.e., negated atoms ) into atoms bodies.
To overcome this problem, we present a method for effective revision of learned Horn rules by adding exceptions ) into atoms bodies.
This way errors are largely reduced.
We apply We method to discover rules with exceptions from real-world large knowledge graphs.
We experimental results demonstrate the effectiveness of the improvements in accuracy for large knowledge graph completion by rule-based fact prediction.
We experimental results demonstrate the effectiveness of the developed method.