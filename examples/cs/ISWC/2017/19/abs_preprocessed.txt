The task of answering natural language questions over RDF data has received wide interest in recent years, in particular in the context of the series of QALD benchmarks.
The task of answering natural language questions over RDF data consists of mapping a natural language question to an executable form, e.g. SPARQL, so that answers from a given KB can be extracted.
So far, most systems proposed are -LRB- i -RRB- monolingual and -LRB- ii -RRB- rely on a set of hard-coded rules to interpret questions most systems into a SPARQL query.
So far, most systems proposed are -LRB- i -RRB- monolingual and -LRB- ii -RRB- rely on a set of hard-coded rules to interpret map most systems into a SPARQL query.
We present the first multilingual QALD pipeline that induces a model from training data for mapping a natural language question into logical form as probabilistic inference.
In particular, We approach learns to map universal syntactic dependency representations to a language-independent logical form based on DUDES -LRB- Dependency-based Underspecified Discourse Representation Structures -RRB- that are then mapped to a SPARQL query as a deterministic second step.
We model builds on factor graphs that rely on features extracted from the dependency graph and corresponding semantic representations.
We rely on approximate inference techniques, Markov Chain Monte Carlo methods in particular Rank to update using a ranking objective.
We rely on approximate inference techniques, Markov Chain Monte Carlo methods in Sample Rank to update using a ranking objective.
We focus lies on developing methods that overcome the lexical gap and present a novel combination of machine translation and word embedding approaches for this purpose.
As a proof of concept for We approach, We evaluate our approach on the QALD-6 datasets for English.
As a proof of concept for We approach, We evaluate our approach on the QALD-6 datasets for Spanish.
As a proof of concept for We approach, We evaluate our approach on the QALD-6 datasets for German.