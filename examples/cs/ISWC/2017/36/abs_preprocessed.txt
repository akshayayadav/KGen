Entity alignment is the task of finding entities in two knowledge bases that represent the same real-world object.
When facing entities in two knowledge bases in different natural languages, conventional cross-lingual entity alignment methods rely on machine translation to eliminate the language barriers.
These approaches often suffer from the uneven quality of translations between languages.
While recent embedding-based techniques encode relationships in the entities in two knowledge bases, a significant number of attributes remain largely unexplored.
While recent embedding-based techniques do not need machine translation for cross-lingual entity alignment, a significant number of attributes remain largely unexplored.
While recent embedding-based techniques encode entities in the entities in two knowledge bases, a significant number of attributes remain largely unexplored.
While recent embedding-based techniques do not need machine translation for cross-lingual entity alignment, a significant number of attributes remain largely unexplored.
In this paper, we propose a joint attribute-preserving embedding model for cross-lingual entity alignment.
a joint attribute-preserving embedding model for cross-lingual entity alignment jointly embeds the structures of two entities in two knowledge bases into a unified vector space and further refines a joint attribute-preserving embedding model for cross-lingual entity alignment by leveraging attribute correlations in the entities in two knowledge bases.
Our experimental results on real-world datasets show that this approach could be complemented with based on machine translation.
Our experimental results on real-world datasets show that this approach significantly outperforms the state-of-the-art embedding approaches for cross-lingual entity alignment.