Many question answering systems over knowledge graphs rely on linking components in order to connect the natural language input to the underlying knowledge graph.
Many question answering systems over knowledge graphs rely on linking components in order to connect the natural language input to the underlying knowledge graph.
Traditionally, linking have been performed either as dependent sequential tasks or as independent parallel tasks.
In this paper, we propose a framework called EARL, which performs entity linking and relation linking as a joint task.
EARL implements two different solution strategies for which we provide a comparative analysis in this paper: The first strategy is a formalisation of the joint entity and relation linking tasks as an instance of the Generalised Travelling Salesman Problem -LRB- GTSP -RRB-.
In order to be computationally feasible, we employ approximate GTSP solvers.
The first strategy uses machine learning in order to exploit the connection density between nodes in the knowledge graph.
The first strategy relies on three base features in order to predict entities.
The first strategy relies on three base features in order to predict relations.
The first strategy relies on re-ranking steps in order to predict entities.
The first strategy relies on re-ranking steps in order to predict relations.
We evaluate the strategies on a dataset with 5000 questions.
We compare the strategies.
the strategies significantly outperform the current state-of-the-art approaches for linking.
the strategies significantly outperform the current state-of-the-art approaches for linking.