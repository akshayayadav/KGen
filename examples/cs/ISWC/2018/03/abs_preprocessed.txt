Knowledge Graphs are widely used abstractions to represent entity-centric knowledge.
Approaches to embed represented in the graph into vector spaces- often referred to as Knowledge Graphs embeddings- have become increasingly popular for entities, represented in the graph into vector spaces- often referred to as Knowledge Graphs embeddings- ability to capture the similarity between entities.
Approaches to embed represented in the graph into vector spaces- often referred to as Knowledge Graphs embeddings- have become increasingly popular for entities, represented in the graph into vector spaces- often referred to as Knowledge Graphs embeddings- ability to capture support other reasoning tasks.
However, representation of time has received little attention in these approaches.
In this work, we make a first step to encode time into using named Typed Entity Embeddings.
In Typed Entity Embeddings, each entity is represented by a vector that represents the entity and the entity type, which is learned from entity mentions found in a text corpus.
Inspired by evidence from cognitive sciences and application-oriented concerns, we propose an approach to encode representations of years into Typed Entity Embeddings by aggregating the representations of the entities that occur in event-based descriptions of the years.
the representations of the entities that occur in event-based descriptions of the years are used to define two time-aware similarity measures to control the implicit effect of time on entity similarity.
Experimental results show that the linear order of obtained using our model is highly correlated with natural time flow to flatten the time effect on entity similarity.
Experimental results show that the linear order of obtained using our model is highly correlated with the effectiveness of proposed to flatten the time effect on entity similarity.