Many approaches for Knowledge Extraction and Ontology Population rely on well-known Natural Language Processing -LRB- NLP -RRB- tasks, such as Named Entity Recognition and Classification and Entity Linking, to identify and semantically characterize the entities mentioned in natural language text.
Despite being intrinsically related, the analyses performed by well-known Natural Language Processing -LRB- NLP -RRB- tasks, such as Named Entity Recognition and Classification and Entity Linking, to identify differ, and combining well-known Natural Language Processing -LRB- NLP -RRB- tasks, such as Named Entity Recognition and Classification and Entity Linking, to identify output may result in NLP annotations that are implausible or even conflicting considering common world knowledge about entities.
In this paper we present a Probabilistic Soft Logic model that leverages ontological entity classes to relate NLP annotations from different tasks insisting on the same entity mentions.
The intuition behind a Probabilistic Soft Logic model that leverages ontological entity classes to relate NLP annotations from different tasks insisting on the same entity is that an annotation likely implies some ontological classes on the entity identified by the same mention, and annotations from different tasks on the same mention have to share more or less the same implied entity classes.
In a setting with various NLP tools returning multiple, confidence-weighted, candidate annotations on a single mention, a Probabilistic Soft Logic model that leverages ontological entity classes to relate NLP annotations from different tasks insisting on the same entity can be operationally applied to compare the different annotation combinations, and to possibly revise the tools' best annotation choice.
We experimented applying a Probabilistic Soft Logic model that leverages ontological entity classes to relate NLP annotations from different tasks insisting on the same entity with the candidate annotations produced by two state-of-the-art tools for Entity Recognition and Classification and Entity Linking, on three different datasets.
The results show that the joint `` a posteriori '' annotation revision suggested by a Probabilistic Soft Logic model that leverages ontological entity classes to relate NLP annotations from different tasks insisting on the same entity consistently improves the original scores of the two tools.