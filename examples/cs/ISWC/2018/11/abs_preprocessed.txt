Information Extraction refers to automatically extracting structured relation tuples from unstructured texts.
Common Information Extraction solutions, including Relation Extraction and open Information Extraction systems, can hardly handle cross-sentence tuples, and are severely restricted by limited relation types as well as informal relation specifications -LRB- e.g., free-text based relation tuples -RRB-.
In order to overcome these weaknesses, we propose a novel Information Extraction framework named QA4IE, which leverages the flexible question answering approaches to produce high quality relation triples across sentences.
Based on a novel Information Extraction framework named QA4IE, which leverages the flexible question answering approaches to produce high quality relation triples across sentences, we develop a large Information Extraction benchmark with high quality human evaluation.
This benchmark contains 293K documents.
This benchmark contains 2M golden relation triples.
This benchmark contains 636 relation types.
We compare We system with some Information Extraction baselines on We benchmark and the results show that our system achieves great improvements.