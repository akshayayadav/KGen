The last decade of research in ontology alignment has brought a variety of computational techniques to discover correspondences between ontologies.
domain knowledge that is used to train the algorithms.
domain knowledge that is used to augment.
domain knowledge that is used to validate.
While the accuracy of automatic approaches has continuously improved, human contributions remain a key ingredient of the process: this input serves as a valuable source of domain knowledge automatically computed alignments.
In this paper, we introduce CrowdMap .
In this paper, we introduce a model to acquire such human contributions via microtask crowdsourcing.
microtasks that evaluates the quality of the results.
microtasks that address individual alignment questions.
microtasks that publishes the microtasks on an online labor market.
For a given pair of ontologies, CrowdMap, a model to acquire such human contributions via microtask crowdsourcing translates the alignment problem into microtasks.
the results obtained from the crowd.
We evaluated the current implementation of a model to acquire such human contributions via microtask crowdsourcing in a series of The experiments Initiative.
We evaluated the current implementation of CrowdMap.
a series of The experiments using reference alignments from the Ontology Alignment Evaluation.
a series of The experiments using ontologies from the Ontology Alignment Evaluation.
We evaluated the current implementation of a model to acquire such human contributions via microtask crowdsourcing in a series of The experiments the crowdsourcing platform CrowdFlower.
The experiments clearly demonstrated that the overall approach is feasible.
The experiments clearly can improve the accuracy of existing ontology alignment solutions in a cost-effective manner.
The experiments clearly can improve the accuracy of existing ontology alignment solutions in a scalable manner.
The experiments clearly can improve the accuracy of existing ontology alignment solutions in a fast manner.