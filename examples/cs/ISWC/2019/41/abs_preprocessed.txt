In the distributed ontology alignment construction problem, two agents agree upon a meaningful subset of correspondences that map between two agents respective ontologies.
However, an agent may be tempted to manipulate the negotiation in favour of a preferred alignment by misrepresenting the weight or confidence of the exchanged correspondences.
Therefore such an agreement can only be meaningful if the agents can be incentivised to be honest when revealing information.
We examine model as a novel mechanism design problem on an edge-weighted bipartite graph, where each side of the graph represents each agent's private entities, and where each agent maintains a private set of associated with model candidate correspondences.
We examine model as a novel mechanism design problem on an edge-weighted bipartite graph, where each side of the graph represents each agent's private entities, and where each agent maintains a private set of associated with this problem.
We examine this problem and model this problem on an edge-weighted bipartite graph, where each side of the graph represents each agent's private entities, and where each agent maintains a private set of associated with this problem.
We examine this problem and model this problem on an edge-weighted bipartite graph, where each side of the graph represents each agent's private entities, and where each agent maintains a private set of associated with model candidate correspondences.
The objective is to find a matching that maximises the agents' social welfare.
We show that implementations in dominant strategies should be solved optimally if truthful mechanisms are required.
We study implementations in dominant strategies.
A decentralised version of the greedy allocation algorithm is then studied with a first-price payment rule, proving tight bounds on the Price of Stability.
A decentralised version of the greedy allocation algorithm is then studied with a first-price payment rule, proving tight bounds on the Price of Anarchy.