In the distributed ontology alignment construction problem, two agents agree upon a meaningful subset of correspondences that map between two agents respective ontologies.
However, an agent may be tempted to manipulate the negotiation in favour of a preferred alignment by misrepresenting the weight or confidence of the exchanged correspondences.
Therefore such an agreement can only be meaningful if the agents can be incentivised to be honest when revealing information.
We examine this problem and model this problem on an edge-weighted bipartite graph, where each side of the graph represents each agent's private entities, and where each agent maintains a private set of associated with model candidate correspondences.
We examine this problem and model this problem on an edge-weighted bipartite graph, where each side of the graph represents each agent's private entities, and where each agent maintains a private set of associated with this problem.
We examine model as a novel mechanism design problem on an edge-weighted bipartite graph, where each side of the graph represents each agent's private entities, and where each agent maintains a private set of associated with model candidate correspondences.
We examine model as a novel mechanism design problem on an edge-weighted bipartite graph, where each side of the graph represents each agent's private entities, and where each agent maintains a private set of associated with this problem.
The objective is to find a matching -LRB- i.e. injective or one-to-one correspondences -RRB- that maximises the agents' social welfare.
We study implementations in dominant strategies.
We show that the agents' should be solved optimally if truthful mechanisms are required.
A decentralised version of the greedy allocation algorithm is then studied with a first-price payment rule, proving tight bounds on the Price of Anarchy.
A decentralised version of the greedy allocation algorithm is then studied with a first-price payment rule, proving tight bounds on the Price of Stability.