Many methods have been proposed to automatically extend knowledge bases, but the vast majority of Many methods focus on finding plausible knowledge graph triples in particular.
Many methods have been proposed to automatically extend knowledge bases, but the vast majority of Many methods focus on finding plausible missing facts graph triples in particular.
In this paper, we instead focus on automatically extending ontologies that are encoded as a set of existential rules.
In particular, we aim is to find rules that are plausible, but which can not be deduced from the given ontology.
To this end, we propose a graph-based representation of rule bases.
Nodes of considered graphs correspond to predicates, and Nodes of considered graphs are annotated with The vectors.
The vectors may be obtained from external resources such as word embeddings could be estimated from the rule base the rule base itself.
The vectors may be obtained from external resources such as The vectors could be estimated from the rule base the rule base itself.
Edges connect predicates that co-occur in The vectors annotations reflect the types of rules in which the predicates co-occur.
Edges connect predicates that co-occur in the same rule reflect the types of rules in which the predicates co-occur.
We then use a neural network model based on Graph Convolutional Networks to refine the initial vector representation of the predicates, to obtain a representation which is predictive of which rules are plausible.
We present experimental results that demonstrate the strong performance of this method.